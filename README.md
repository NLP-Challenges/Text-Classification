# Text-Classification

****MC1 (LE3-LE5)****

## Model Selection
Begr√ºnden, wieso wir diese Architekturen/Modelle verwenden

Mindestens 1 System Fine-Tuned

- ****TF-IDF und Hist Gradient Boost / SVM****
    - Tokenization
- **Transformer (oder anderes DL-Modell) / CNN**
    - Word-to-Vec / Doc-to-Vec
    - Fine-Tuned Model
    - BERT (Transformer, Embeddings) / LLAMA?
        
        [BERT](https://huggingface.co/docs/transformers/model_doc/bert)
        

To perform the tasks in a chronological and logical order, follow these bullet points:

## Plan

1. **Form a Group of 2**
    - Find a partner to collaborate with on the project
    - Establish communication and project management protocols
2. **Selection of Classification Systems**
    - Conduct preliminary research on various classification systems such as tf-idf-svm, cnns, or transformers
    - Choose two different classification systems, with at least one being a fine-tuned deep learning model
    - Draft initial arguments for the selection of the chosen systems based on their underlying theories
3. **Dataset Acquisition**
    - Identify and select an appropriate dataset for text classification from platforms such as semeval, kaggle, codalab, or paperwithcode
    - Ensure the dataset selected is not the 20newsgroup dataset as it is already in use
4. **Repository Setup**
    - Set up a GitLab repository for the project
    - Organize the repository to include sections for the report, a Python notebook, and a wiki or git issues for documenting progress
5. **System Building**
    - Develop the chosen classification systems, ideally implementing them from scratch for bonus points
    - Start documenting the build process and any encountered errors in the repository's wiki or git issues
6. **System Training**
    - Train the developed classification systems using the chosen dataset
    - Log the training progress and any noteworthy observations in the repository
7. **System Evaluation**
    - Evaluate the performance of the systems using appropriate metrics
    - Document the selected metrics and justify their choice in the context of the project's use case
8. **Error Analysis**
    - Conduct a thorough error analysis of both systems
    - Propose theories for potential improvements based on the analysis, focusing especially on individual cases and comparative predictions
9. **Report Compilation**
    - Begin compiling a detailed report, incorporating sections that describe the chosen systems, their theoretical background, and the rationale behind their selection
    - Include an evaluation section detailing the chosen metrics and a discussion on the results of the experiments, along with predictions on individual test samples
10. **Submission Preparation**
    - Prepare the project for submission, ensuring that the GitLab repository includes the report, a Python notebook to reproduce the results, and a well-documented wiki or git issues section
    - Verify that both group members have made significant contributions, as evidenced by the commit history
11. **Submission**
    - Submit the project through the GitLab repository, adhering to any additional submission guidelines provided.
