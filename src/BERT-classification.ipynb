{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Callback\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "import wandb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Classifier\n",
    "\n",
    "Our BERT classifier for the Data Chatbot.\n",
    "\n",
    "**Relevant Resources**\n",
    "\n",
    "- https://docs.wandb.ai/guides/integrations/lightning#logger-arguments\n",
    "- https://pytorch-lightning.readthedocs.io/en/0.9.0/hyperparameters.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.text\n",
    "        self.labels = dataframe.label\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split()) # Removes any extra whitespace\n",
    "\n",
    "        # https://huggingface.co/docs/transformers/v4.34.0/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True, # Add '[CLS]' and '[SEP]', default True\n",
    "            max_length=self.max_len, # Maximum length to use by one of the truncation/padding parameters\n",
    "            padding='max_length', # Pad to a maximum length specified with the argument max_length\n",
    "            truncation=True, # Truncate to a maximum length specified with the argument max_length\n",
    "        )\n",
    "        ids = inputs['input_ids'] # Indices of input sequence tokens in the vocabulary\n",
    "        mask = inputs['attention_mask'] # Mask to avoid performing attention on padding token indices\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(self.labels[index], dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "\n",
    "# Load data and return DataLoader\n",
    "def get_dataloader(df, tokenizer, max_len=None, batch_size=32, shuffle=True, nobatch=False):\n",
    "    \"\"\"\n",
    "    Loads data into a PyTorch DataLoader object.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The data frame containing the text and labels.\n",
    "    - tokenizer (Tokenizer): The tokenizer to be used.\n",
    "    - max_len (int, optional): The maximum length for the tokenized sequences. Defaults to None (model's limitation).\n",
    "    - batch_size (int, optional): The size of each batch. Defaults to 32.\n",
    "    - shuffle (bool, optional): Whether to shuffle the data. Defaults to True.\n",
    "    - nobatch (bool, optional): Whether to disable batching. If True, batch_size will be set to the length of df. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "    - DataLoader: A PyTorch DataLoader object containing the tokenized data.\n",
    "\n",
    "    Notes:\n",
    "    - The label mapping {'harm': 0, 'question': 1, 'concern': 2} is applied to the labels in df.\n",
    "    \"\"\"\n",
    "    label_mapping = {'harm': 0, 'question': 1, 'concern': 2}\n",
    "    df['label'] = df['label'].map(label_mapping)\n",
    "    dataset = ClassifierDataset(df, tokenizer, max_len)\n",
    "\n",
    "    # Handle nobatch\n",
    "    batch_size = batch_size if not nobatch else df.__len__()\n",
    "    print(f\"DataLoader | No Batch: {nobatch}; Batch Size: {batch_size}\")\n",
    "\n",
    "    # Create DataLoader\n",
    "    params = {'batch_size': batch_size, 'shuffle': shuffle, 'num_workers': 0}\n",
    "    data_loader = DataLoader(dataset, **params)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(pl.LightningModule, PyTorchModelHubMixin):\n",
    "    def __init__(self, hparams):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "\n",
    "        # Save hyperparameters\n",
    "        self.hparams.update(hparams)\n",
    "        self.__configure_from_hyperparams()\n",
    "\n",
    "        self.model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=3)\n",
    "    \n",
    "    def forward(self, ids, mask):\n",
    "        output = self.model(ids, attention_mask=mask)\n",
    "        return output.logits\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        return self.__step(batch, batch_nb, 'train')\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        return self.__step(batch, batch_nb, 'val')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-5)\n",
    "\n",
    "    def save_pretrained(self, *args, **kwargs):\n",
    "        # Forward all arguments to the inner Bert model's save_pretrained method\n",
    "        self.model.save_pretrained(*args, **kwargs)\n",
    "\n",
    "    def push_to_hub(self, *args, **kwargs):\n",
    "        # Forward all arguments to the inner Bert model's push_to_hub method\n",
    "        self.model.push_to_hub(*args, **kwargs)\n",
    "\n",
    "    def __configure_from_hyperparams(self):\n",
    "        # Set N/A hyperparameters to default values\n",
    "        self.max_len = self.hparams.get(\"max_len\", 100)\n",
    "        self.batch_size =  self.hparams.get(\"batch_size\", 32)\n",
    "\n",
    "    def __step(self, batch, batch_idx, stage):\n",
    "        preds, loss, accuracy, f1 = self.__get_preds_loss_accuracy(batch)\n",
    "        \n",
    "        self.log(\n",
    "            f'{stage}/accuracy',\n",
    "            accuracy,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "        self.log(\n",
    "            f'{stage}/f1',\n",
    "            f1,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "        self.log(f'{stage}/loss', loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def __get_preds_loss_accuracy(self, batch):\n",
    "        # Helper function to get predictions and loss\n",
    "        ids = batch['ids']\n",
    "        mask = batch['mask']\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        preds = self(ids, mask)\n",
    "        loss = torch.nn.CrossEntropyLoss()(preds, labels)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(preds, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        total = labels.size(0)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        # Calculate F1 score\n",
    "        labels_cpu = labels.cpu().numpy()\n",
    "        predicted_cpu = predicted.cpu().numpy()\n",
    "        f1 = f1_score(labels_cpu, predicted_cpu, average='macro')\n",
    "        f1 = np.float32(f1)\n",
    "\n",
    "        return preds, loss, accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrixLogger(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.preds = []\n",
    "        self.targets = []\n",
    "\n",
    "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        ids = batch['ids']\n",
    "        mask = batch['mask']\n",
    "        labels = batch['labels']\n",
    "        preds = pl_module(ids, mask)\n",
    "        ground_truth_ids = labels.flatten().cpu().numpy()\n",
    "\n",
    "        self.preds.extend(preds.cpu().numpy())\n",
    "        self.targets.extend(ground_truth_ids)\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        all_labels = ['harm', 'question', 'concern']\n",
    "\n",
    "        # Log the confusion matrix\n",
    "        wandb.log({\"confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "            preds=np.argmax(np.array(self.preds), axis=1), y_true=self.targets, class_names=all_labels)\n",
    "        })\n",
    "\n",
    "        # Log the ROC curve\n",
    "        probabilites = torch.nn.functional.softmax(torch.tensor(self.preds), dim=1)\n",
    "        wandb.log({\"roc\" : wandb.plot.roc_curve(\n",
    "            y_true=self.targets, y_probas=probabilites, labels=all_labels, classes_to_plot=None)\n",
    "        })\n",
    "\n",
    "        # Clear for the next epoch\n",
    "        self.preds = []\n",
    "        self.targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_bert(run_config, train_dataloader, val_dataloader):\n",
    "    # WandB initialization \n",
    "    wandb.login()\n",
    "\n",
    "    # Initialize model\n",
    "    model = BERTClassifier(hparams=run_config)\n",
    "\n",
    "    # Initialize WandbLogger\n",
    "    wandb_logger = WandbLogger(entity='yvokeller', project='data-chatbot') # log_model='all'\n",
    "    wandb_logger.experiment.config.update(run_config)\n",
    "\n",
    "    # Create an instance of the ConfusionMatrixLogger class\n",
    "    confusion_matrix_logger = ConfusionMatrixLogger()\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=run_config.get('epochs'), \n",
    "        logger=wandb_logger,\n",
    "        callbacks=[confusion_matrix_logger],\n",
    "        log_every_n_steps=1, \n",
    "        enable_progress_bar=True,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model, train_dataloader, val_dataloader)\n",
    "\n",
    "    # Close WandB logger\n",
    "    wandb.finish()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune BERT Model\n",
    "\n",
    "### POC with Simple Demo Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB initialization \n",
    "wandb.login()\n",
    "\n",
    "# Config\n",
    "run_config = {\n",
    "    'epochs': 5,\n",
    "    'max_len': 100,\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Load training and validation data\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "train_dataloader = get_dataloader(train_df, tokenizer, max_len=run_config.get('max_len'), batch_size=run_config.get('batch_size'))\n",
    "\n",
    "val_df = pd.read_csv('data/val.csv')\n",
    "val_dataloader = get_dataloader(val_df, tokenizer, run_config.get('max_len'), batch_size=run_config.get('batch_size'), shuffle=False, nobatch=True)\n",
    "\n",
    "# Finetune BERT\n",
    "model = finetune_bert(run_config, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit on a small sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Config\n",
    "run_config = {\n",
    "    'epochs': 10,\n",
    "    'max_len': None,\n",
    "    'batch_size': 16\n",
    "}\n",
    "\n",
    "# Load training and validation data\n",
    "train_df = pd.read_parquet('../data/train.parquet')\n",
    "train_df, _ = train_test_split(train_df, train_size=64, random_state=42, stratify=train_df['label'])\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "print('train', train_df.shape)\n",
    "train_dataloader = get_dataloader(train_df, tokenizer, max_len=run_config.get('max_len'), batch_size=run_config.get('batch_size'))\n",
    "\n",
    "val_df = pd.read_parquet('../data/test.parquet')\n",
    "val_df, _ = train_test_split(val_df, train_size=64, random_state=42, stratify=val_df['label'])\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "print('val', val_df.shape)\n",
    "val_dataloader = get_dataloader(val_df, tokenizer, run_config.get('max_len'), batch_size=run_config.get('batch_size'), shuffle=False, nobatch=True)\n",
    "\n",
    "# Fine-tune BERT\n",
    "model = finetune_bert(run_config, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Config\n",
    "run_config = {\n",
    "    'epochs': 6,\n",
    "    'max_len': None,\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "# Load training and validation data\n",
    "train_df = pd.read_parquet('../data/train.parquet')\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "print('train', train_df.shape)\n",
    "train_dataloader = get_dataloader(train_df, tokenizer, max_len=run_config.get('max_len'), batch_size=run_config.get('batch_size'))\n",
    "\n",
    "val_df = pd.read_parquet('../data/test.parquet')\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "print('val', val_df.shape)\n",
    "val_dataloader = get_dataloader(val_df, tokenizer, run_config.get('max_len'), batch_size=run_config.get('batch_size'), shuffle=False, nobatch=True)\n",
    "\n",
    "model = finetune_bert(run_config, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "The model achieved a validation accuracy of 97.8% after training. We are **concerned** that it **overfits on the question mark** for classifying questions, which we need to investigate further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with 50% of Question Marks removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_question_marks(df, frac, verbose=True):\n",
    "    # Select 50% of the rows with label \"question\"\n",
    "    question_rows = df[df['label'] == 'question'].sample(frac=0.5, random_state=42)\n",
    "\n",
    "    # Replace question marks with empty strings\n",
    "    question_rows['text'] = question_rows['text'].str.replace('?', '')\n",
    "\n",
    "    # Update the original dataframe with the modified rows\n",
    "    df.update(question_rows)\n",
    "\n",
    "    if verbose:\n",
    "        print('Total questions processed:', df['label'].value_counts())\n",
    "        print('Total questions which still have a ?:',  df['text'].str.count('\\?').sum())\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions processed: label\n",
      "question    358\n",
      "harm        358\n",
      "concern     358\n",
      "Name: count, dtype: int64\n",
      "Total questions which still have a ?: 226\n",
      "train (1074, 2)\n",
      "DataLoader | No Batch: False; Batch Size: 32\n",
      "Total questions processed: label\n",
      "question    88\n",
      "harm        88\n",
      "concern     88\n",
      "Name: count, dtype: int64\n",
      "Total questions which still have a ?: 58\n",
      "val (264, 2)\n",
      "DataLoader | No Batch: True; Batch Size: 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20231105_230339-81k57e2p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yvokeller/data-chatbot/runs/81k57e2p' target=\"_blank\">cosmic-star-50</a></strong> to <a href='https://wandb.ai/yvokeller/data-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yvokeller/data-chatbot' target=\"_blank\">https://wandb.ai/yvokeller/data-chatbot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yvokeller/data-chatbot/runs/81k57e2p' target=\"_blank\">https://wandb.ai/yvokeller/data-chatbot/runs/81k57e2p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type                          | Params\n",
      "--------------------------------------------------------\n",
      "0 | model | BertForSequenceClassification | 177 M \n",
      "--------------------------------------------------------\n",
      "177 M     Trainable params\n",
      "0         Non-trainable params\n",
      "177 M     Total params\n",
      "711.423   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c35cc3bd4ab425cb99725bb2067f301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/deep-learning/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/deep-learning/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e20a1e90fe4131ad715e2c145b4bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58083bd120804a40bfbc73eede555c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39eaca332b894e898cf443714bf39c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab1cd4411ec444a9684f779214c1a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c699f054ff64a2aab4e1852ad5cc8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0078c276f5da4e79bd9309a41b75c8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6dacf967314edba2c0f7214b9ffa84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.033 MB of 0.034 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.982300…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████</td></tr><tr><td>train/accuracy_epoch</td><td>▁▆███</td></tr><tr><td>train/accuracy_step</td><td>▁▆▇▇▇█▇▇▇▇█▇██▇██████████▇██████████████</td></tr><tr><td>train/f1_epoch</td><td>▁▇███</td></tr><tr><td>train/f1_step</td><td>▁▆▇▇▇█▇▇▇▇█▇██▇██████████▇██████████████</td></tr><tr><td>train/loss</td><td>█▇▆▅▄▄▃▃▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▁▂▃▃▃▃▃▄▁▄▄▄▄▅▅▅▁▅▅▆▆▆▆▆▁▇▇▇▇████</td></tr><tr><td>val/accuracy_epoch</td><td>▁▇▇█▆</td></tr><tr><td>val/accuracy_step</td><td>▁▇▇█▆</td></tr><tr><td>val/f1_epoch</td><td>▁▇▇█▆</td></tr><tr><td>val/f1_step</td><td>▁▇▇█▆</td></tr><tr><td>val/loss</td><td>█▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train/accuracy_epoch</td><td>0.99907</td></tr><tr><td>train/accuracy_step</td><td>1.0</td></tr><tr><td>train/f1_epoch</td><td>0.99917</td></tr><tr><td>train/f1_step</td><td>1.0</td></tr><tr><td>train/loss</td><td>0.01104</td></tr><tr><td>trainer/global_step</td><td>169</td></tr><tr><td>val/accuracy_epoch</td><td>0.97727</td></tr><tr><td>val/accuracy_step</td><td>0.97727</td></tr><tr><td>val/f1_epoch</td><td>0.9772</td></tr><tr><td>val/f1_step</td><td>0.9772</td></tr><tr><td>val/loss</td><td>0.07947</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cosmic-star-50</strong> at: <a href='https://wandb.ai/yvokeller/data-chatbot/runs/81k57e2p' target=\"_blank\">https://wandb.ai/yvokeller/data-chatbot/runs/81k57e2p</a><br/>Synced 6 W&B file(s), 12 media file(s), 12 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231105_230339-81k57e2p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Config\n",
    "run_config = {\n",
    "    'epochs': 5,\n",
    "    'max_len': None,\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "# Load training and validation data\n",
    "train_df = pd.read_parquet('../data/train.parquet')\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = remove_question_marks(train_df, 0.5)\n",
    "print('train', train_df.shape)\n",
    "train_dataloader = get_dataloader(train_df, tokenizer, max_len=run_config.get('max_len'), batch_size=run_config.get('batch_size'))\n",
    "\n",
    "val_df = pd.read_parquet('../data/test.parquet')\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "val_df = remove_question_marks(val_df, 0.5)\n",
    "print('val', val_df.shape)\n",
    "val_dataloader = get_dataloader(val_df, tokenizer, run_config.get('max_len'), batch_size=run_config.get('batch_size'), shuffle=False, nobatch=True)\n",
    "\n",
    "model = finetune_bert(run_config, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "Even with 50% of the question marks removed, the model showed in an experiment ran on the whole dataset, but with 50% of the question marks removed, that it is able to achieve a great validation accuracy of 98.8%. This is a good sign, as it shows that the model is not just basing its predictions on the question mark.\n",
    "\n",
    "https://wandb.ai/yvokeller/data-chatbot/runs/81k57e2p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist model locally\n",
    "\n",
    "For evaluation purposes, we want to persist the model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert-classifier/tokenizer/tokenizer_config.json',\n",
       " 'bert-classifier/tokenizer/special_tokens_map.json',\n",
       " 'bert-classifier/tokenizer/vocab.txt',\n",
       " 'bert-classifier/tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('bert-classifier/model')\n",
    "tokenizer.save_pretrained('bert-classifier/tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load model locally\n",
    "loaded_model = BertForSequenceClassification.from_pretrained('bert-classifier/model', num_labels=3)\n",
    "loaded_tokenizer = BertTokenizer.from_pretrained('bert-classifier/tokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist model on HuggingFace\n",
    "\n",
    "Our BERT classifier for the Data Chatbot is published here: https://huggingface.co/nlpchallenges/Text-Classification/tree/main\n",
    "\n",
    "Before pushing to the hub for the first time, make sure to run `huggingface-cli login` in your terminal, and paste the API token from your HuggingFace profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca99d6c56e38455fbcdbbbfbc636520b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/711M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/nlpchallenges/Text-Classification/commit/5379bc72a25f3381fc2c2e3174f3632ef4b6408a', commit_message='Upload tokenizer', commit_description='', oid='5379bc72a25f3381fc2c2e3174f3632ef4b6408a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"nlpchallenges/Text-Classification\")\n",
    "tokenizer.push_to_hub(\"nlpchallenges/Text-Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6f79c778494b4abaee68c0d644b33a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.45k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3917f3efee114b2f9792af7aa1f3dc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae36849d6b345da9b3f35cc58b9bc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/82.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edeef31c7816472696b45c539d1b5e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865873a73b434631ad16351995ff41f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1096b84181f64c448dc40914b5722944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/711M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_tokenizer = BertTokenizer.from_pretrained('nlpchallenges/Text-Classification')\n",
    "loaded_model = BertForSequenceClassification.from_pretrained('nlpchallenges/Text-Classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "def classify_text(user_input, model, tokenizer, max_len=100):\n",
    "    # Tokenize the user input\n",
    "    inputs = tokenizer(\n",
    "        user_input,\n",
    "        None,\n",
    "        add_special_tokens=True, # Add '[CLS]' and '[SEP]', default True\n",
    "        max_length=max_len, # Maximum length to use by one of the truncation/padding parameters\n",
    "        padding='max_length', # Pad to a maximum length specified with the argument max_length\n",
    "        truncation=True, # Truncate to a maximum length specified with the argument max_length\n",
    "    )\n",
    "\n",
    "    ids = torch.tensor(inputs['input_ids'], dtype=torch.long).unsqueeze(0) # Indices of input sequence tokens in the vocabulary\n",
    "    mask = torch.tensor(inputs['attention_mask'], dtype=torch.long).unsqueeze(0) # Mask to avoid performing attention on padding token indices\n",
    "    \n",
    "    \n",
    "    # Get model output\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(ids, attention_mask=mask)\n",
    "    \n",
    "    # Get predicted label index\n",
    "    _, predicted_idx = torch.max(output.logits, 1)\n",
    "    \n",
    "    # Map index to label\n",
    "    label_mapping = {0: 'harm', 1: 'question', 2: 'concern'}\n",
    "    return label_mapping[predicted_idx.item()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'concern'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_text(\"du bist sehr intelligent\", loaded_model, loaded_tokenizer, max_len=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ich bin sehr aufgeregt</td>\n",
       "      <td>concern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>was muss ich im modul EDA machen?</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ich habe angst</td>\n",
       "      <td>harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ich bin sehr glücklich</td>\n",
       "      <td>concern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>du bist sehr intelligent</td>\n",
       "      <td>concern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weisst du wie das wetter heute wird?</td>\n",
       "      <td>harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>denkst du ich bin intelligent</td>\n",
       "      <td>harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wohin muss ich morgen</td>\n",
       "      <td>harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>damn du bist ein schlechter chatbot</td>\n",
       "      <td>harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>was für ein idiot</td>\n",
       "      <td>harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>erzähl mir mal einen witz</td>\n",
       "      <td>harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ich bin sehr traurig</td>\n",
       "      <td>concern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ich kann mich nicht erinnern wer das modul ALA...</td>\n",
       "      <td>harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>was macht ein affe auf dem baum?</td>\n",
       "      <td>harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ich bin sehr wütend</td>\n",
       "      <td>harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wer hat python erfunden?</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mothafucka</td>\n",
       "      <td>harm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text     label\n",
       "0                              ich bin sehr aufgeregt   concern\n",
       "1                   was muss ich im modul EDA machen?  question\n",
       "2                                      ich habe angst      harm\n",
       "3                              ich bin sehr glücklich   concern\n",
       "4                            du bist sehr intelligent   concern\n",
       "5                weisst du wie das wetter heute wird?      harm\n",
       "6                       denkst du ich bin intelligent      harm\n",
       "7                               wohin muss ich morgen      harm\n",
       "8                 damn du bist ein schlechter chatbot      harm\n",
       "9                                   was für ein idiot      harm\n",
       "10                          erzähl mir mal einen witz      harm\n",
       "11                               ich bin sehr traurig   concern\n",
       "12  ich kann mich nicht erinnern wer das modul ALA...      harm\n",
       "13                   was macht ein affe auf dem baum?      harm\n",
       "14                                ich bin sehr wütend      harm\n",
       "15                           Wer hat python erfunden?  question\n",
       "16                                         mothafucka      harm"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_inference(prompts):\n",
    "    # create df to save results\n",
    "    df = pd.DataFrame(columns=['text', 'label'])\n",
    "    for user_input in qualitative_testing:\n",
    "        # classify text and make data frame\n",
    "        label = classify_text(user_input, loaded_model, loaded_tokenizer, max_len=None)\n",
    "        entry = [user_input, label]\n",
    "        df.loc[len(df)] = entry\n",
    "    return df\n",
    "\n",
    "qualitative_testing = {\n",
    "    'weisst du wie das wetter heute wird?',\n",
    "    'denkst du ich bin intelligent',\n",
    "    'wohin muss ich morgen',\n",
    "    'du bist sehr intelligent',\n",
    "    'was für ein idiot',\n",
    "    'ich habe angst',\n",
    "    'ich bin sehr traurig',\n",
    "    'ich bin sehr glücklich',\n",
    "    'ich bin sehr wütend',\n",
    "    'ich bin sehr aufgeregt',\n",
    "    'was muss ich im modul EDA machen?',\n",
    "    'Wer hat python erfunden?',\n",
    "    'was macht ein affe auf dem baum?',\n",
    "    'mothafucka',\n",
    "    'damn du bist ein schlechter chatbot',\n",
    "    'erzähl mir mal einen witz',\n",
    "    'ich kann mich nicht erinnern wer das modul ALA gibt'\n",
    "}\n",
    "\n",
    "apply_inference(qualitative_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qualitative Testing Results**\n",
    "\n",
    "- Seems to not work for passive questions\n",
    "- Identifies too much harm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
